{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns={\n",
    "    '3.feed_1.SO2_PPM': 'SO2_PPM',\n",
    "    '3.feed_1.H2S_PPM': 'H2S_PPM',\n",
    "    '3.feed_1.SIGTHETA_DEG': 'SIGTHETA_DEG',\n",
    "    '3.feed_1.SONICWD_DEG': 'SONICWD_DEG@',\n",
    "    '3.feed_1.SONICWS_MPH': 'SONICWS_MPH',\n",
    "    '3.feed_11067.CO_PPB..3.feed_43.CO_PPB': 'CO_PPB',\n",
    "    '3.feed_11067.NO2_PPB..3.feed_43.NO2_PPB': 'NO2_PPB',\n",
    "    '3.feed_11067.NOX_PPB..3.feed_43.NOX_PPB': 'NOX_PPB',\n",
    "    '3.feed_11067.NO_PPB..3.feed_43.NO_PPB': 'NO_PPB',\n",
    "    '3.feed_11067.PM25T_UG_M3..3.feed_43.PM25T_UG_M3': 'PM2_5_',\n",
    "    '3.feed_11067.SIGTHETA_DEG..3.feed_43.SIGTHETA_DEG': 'SIGTHETA_DEG',\n",
    "    '3.feed_11067.SONICWD_DEG..3.feed_43.SONICWD_DEG': 'SONICWD_DEG@',\n",
    "    '3.feed_11067.SONICWS_MPH..3.feed_43.SONICWS_MPH': 'SONICWS_MPH',\n",
    "    '3.feed_29.PM10_UG_M3': 'PM10_',\n",
    "    '3.feed_3506.PM2_5': 'PM2_5_1',\n",
    "    '3.feed_3506.OZONE': 'OZONE',\n",
    "    '3.feed_24.PM10_UG_M3': 'PM_10',\n",
    "    '3.feed_3508.PM2_5': 'PM_2_5_2',\n",
    "    '3.feed_3.PM10B_UG_M3..3.feed_3.PM10_640_UG_M3': 'PM10_1',\n",
    "    '3.feed_23.CO_PPM..3.feed_23.CO_PPB': 'CO_PPM_CO_PPB',\n",
    "    '3.feed_28.H2S_PPM': 'H2S_PPM',\n",
    "    '3.feed_28.SO2_PPM': 'SO2_PPM',\n",
    "    '3.feed_28.SIGTHETA_DEG': 'SIGTHETA_DEG',\n",
    "    '3.feed_28.SONICWD_DEG': 'SONICWD_DEG@',\n",
    "    '3.feed_28.SONICWS_MPH': 'SONICWS_MPH',\n",
    "    '3.feed_1.PM25B_UG_M3..3.feed_1.PM25T_UG_M3..3.feed_1.PM25_640_UG_M3': 'PM2_5_3',\n",
    "    '3.feed_26.OZONE_PPM': 'OZONE_PPM',\n",
    "    '3.feed_26.SONICWS_MPH': 'SONICWS_MPH',\n",
    "    '3.feed_26.SONICWD_DEG': 'SONICWD_DEG@',\n",
    "    '3.feed_26.SIGTHETA_DEG': 'SIGTHETA_DEG',\n",
    "    '3.feed_3.SO2_PPM': 'SO2_PPM',\n",
    "    '3.feed_3.SONICWD_DEG': 'SONICWD_DEG@',\n",
    "    '3.feed_3.SONICWS_MPH': 'SONICWS_MPH',\n",
    "    '3.feed_3.SIGTHETA_DEG': 'SIGTHETA_DEG',\n",
    "    '3.feed_5975.PM2_5': 'PM2_5_4',\n",
    "    '3.feed_23.PM10_UG_M3': 'PM10_UG_M3',\n",
    "    '3.feed_27.NO_PPB': 'NO_PPB',\n",
    "    '3.feed_27.NOY_PPB': 'NOY_PPB',\n",
    "    '3.feed_27.CO_PPB': 'CO_PPB',\n",
    "    '3.feed_27.SO2_PPB': 'SO2_PPB',\n",
    "    '3.feed_29.PM25_UG_M3..3.feed_29.PM25T_UG_M3': 'PM2_5_5',\n",
    "    '3.feed_26.PM25B_UG_M3..3.feed_26.PM25T_UG_M3..3.feed_59665.PM25_640_UG_M3': 'PM2_5_6',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec le backdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_regression\n",
    "import copy\n",
    "\n",
    "\n",
    "debug=False\n",
    "def get_combination(lst,tuplelst):\n",
    "    i=0\n",
    "    new_tuplelst=[]\n",
    "    if len(tuplelst)==0:\n",
    "        l=lst[0]\n",
    "        for v in l:\n",
    "            new_tuplelst.append([v])\n",
    "        if len(lst)>1:\n",
    "            return get_combination(lst[1:],new_tuplelst)\n",
    "        else:\n",
    "            return new_tuplelst\n",
    "    \n",
    "\n",
    "    currlst=lst[0]\n",
    "    for l in tuplelst:\n",
    "        \n",
    "        for v in currlst:\n",
    "            newl=copy.deepcopy(l)\n",
    "            newl.append(v)\n",
    "            new_tuplelst.append(newl)\n",
    "        \n",
    "    if len(lst)>1:\n",
    "        return get_combination(lst[1:],new_tuplelst)\n",
    "    else:\n",
    "        return new_tuplelst\n",
    "      \n",
    "def get_C_set(df,C):\n",
    "    lst=[]\n",
    "    for Cvar in C:\n",
    "        lst.append(list(set(list(df[Cvar]))))\n",
    "    combination_lst= (get_combination(lst,[]))\n",
    "    return combination_lst\n",
    "\n",
    "def get_val(row,target,target_val):\n",
    "    i=0\n",
    "    while i<len(target):\n",
    "        if not int(row[target[i]])==int(target_val[i]):\n",
    "            return 0\n",
    "        i+=1\n",
    "    return 1\n",
    "\n",
    "def train_regression(df,conditional,conditional_values,target,target_val):\n",
    "    new_lst=[]\n",
    "    count=0\n",
    "    for index,row in df.iterrows():\n",
    "        new_lst.append(get_val(row,target,target_val))\n",
    "        if new_lst[-1]==1:\n",
    "            count+=1\n",
    "    if len(conditional)==0:\n",
    "        return count*1.0/df.shape[0]\n",
    "    if len(list(set(new_lst)))==1:\n",
    "        if new_lst[0]==1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    if len(conditional)>0:\n",
    "        X=df[conditional]\n",
    "    else:\n",
    "        X=df\n",
    "    #print(X)\n",
    "    #print(new_lst)\n",
    "    regr = RandomForestRegressor(random_state=0)\n",
    "    #regr = LogisticRegression(random_state=0)\n",
    "    regr.fit(X.values, new_lst)\n",
    "    return regr\n",
    "\n",
    "def get_prob_o_regression(df,conditional,conditional_values,target,target_val):\n",
    "    new_lst=[]\n",
    "    count=0\n",
    "    for index,row in df.iterrows():\n",
    "        new_lst.append(get_val(row,target,target_val))\n",
    "        if new_lst[-1]==1:\n",
    "            count+=1\n",
    "    if len(conditional)==0:\n",
    "        return count*1.0/df.shape[0]\n",
    "    if len(list(set(new_lst)))==1:\n",
    "        if new_lst[0]==1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    if len(conditional)>0:\n",
    "        X=df[conditional]\n",
    "    else:\n",
    "        X=df\n",
    "    regr = RandomForestRegressor(random_state=0)\n",
    "    #regr = LogisticRegression(random_state=0)\n",
    "    regr.fit(X.values, new_lst)\n",
    "    #print (regr.coef_.tolist())\n",
    "    #print (regr.predict_proba([conditional_values]),\"ASDFDS\")\n",
    "    return (regr.predict([conditional_values])[0])\n",
    "    #return(regr.predict_proba([conditional_values])[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_query_output(df,q_type,AT,prelst,prevallst,postlst,postvallst,Ac,c,g_Ac_lst,interference, blocks):\n",
    "\n",
    "    #print (len(sub_df),len(sub_intervene))\n",
    "    if q_type=='count':\n",
    "        conditioning_set=prelst\n",
    "        #        intervention=\n",
    "        backdoorlst=[]\n",
    "\n",
    "        for attr in Ac:\n",
    "            backdoorlst.extend(backdoor[attr])\n",
    "            print('estoy aqui')\n",
    "        backdoorlst=list(set(backdoorlst))\n",
    "\n",
    "        if len(backdoorlst)>0:\n",
    "            backdoorvals=get_C_set(df,backdoorlst)\n",
    "            #print(backdoorvals)\n",
    "        else:\n",
    "            backdoorvals=[]\n",
    "            \n",
    "        total_prob=0\n",
    "        regr=''\n",
    "        iter=0\n",
    "        print('hola')\n",
    "        for backdoorvallst in backdoorvals:\n",
    "            print('chao')\n",
    "            conditioning_set=[]\n",
    "            conditioning_set.extend(prelst)\n",
    "            #print(conditioning_set)\n",
    "            conditioning_set.extend(Ac)\n",
    "            #print(conditioning_set)\n",
    "            conditioning_set.extend(backdoorlst)\n",
    "            #print(conditioning_set)\n",
    "\n",
    "            conditioning_val=[]\n",
    "            conditioning_val.extend(prevallst)\n",
    "            #print(conditioning_val)\n",
    "            conditioning_val.extend(c)\n",
    "            conditioning_val.extend(backdoorvallst)\n",
    "\n",
    "            print (\"conditioning set\",conditioning_set,conditioning_val)\n",
    "            print(\"post condition\",postlst,postvallst)\n",
    "            if iter==0:\n",
    "                regr=train_regression(df,conditioning_set,conditioning_val,postlst,postvallst)\n",
    "            pogivenck= regr.predict([conditioning_val])[0]#(get_prob_o_regression(df,conditioning_set,conditioning_val,postlst,postvallst))\n",
    "            \n",
    "            \n",
    "            #print(prelst,prevallst,backdoorlst,backdoorvallst)\n",
    "            pcgivenk = (get_prob_o_regression(df,prelst,prevallst,backdoorlst,backdoorvallst))\n",
    "            #print (pogivenck,pcgivenk)\n",
    "            total_prob+=pogivenck * pcgivenk\n",
    "            iter+=1\n",
    "            \n",
    "        #print(\"final prob is \",total_prob)\n",
    "        return total_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data ZIPCODE 15133 for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/merged_data_15133.csv')\n",
    "\n",
    "df.rename(columns=columns, inplace=True)\n",
    "df.rename(columns={'smell_1': 'smell'}, inplace=True)\n",
    "columns_to_evaluate = df.filter(regex='^(?!smell_)').columns.tolist()\n",
    "df = df.dropna(subset=columns_to_evaluate, how='all')\n",
    "df.drop(columns=['DateTime','smell_2','smell_3'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertWindDirection(df):\n",
    "    df_cp = df.copy(deep=True)\n",
    "    for c in df.columns:\n",
    "        if \"SONICWD_DEG\" in c or \"@\" in c:\n",
    "            df_c = df[c]\n",
    "            df_c.name = df_c.name.replace(\"@\", \"\")\n",
    "            df_c_cos = np.cos(np.deg2rad(df_c))\n",
    "            df_c_sin = np.sin(np.deg2rad(df_c))\n",
    "            df_c_cos.name += \"cosine\"\n",
    "            df_c_sin.name += \"sine\"\n",
    "            df_cp.drop([c], axis=1, inplace=True)\n",
    "            df_cp[df_c_cos.name] = df_c_cos\n",
    "            df_cp[df_c_sin.name] = df_c_sin\n",
    "    return df_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null treatment\n",
    "df.iloc[:, 1:] = df.iloc[:, 1:].replace(-1.0, np.nan)\n",
    "df.iloc[:, 1:] = df.iloc[:, 1:].fillna(df.iloc[:, 1:].mean())\n",
    "df['smell'] = df['smell'].fillna('no smell')\n",
    "\n",
    "# wind direction conversion\n",
    "df = convertWindDirection(df)\n",
    "\n",
    "# standardization\n",
    "# df_mean = df.iloc[:, 1:].mean()\n",
    "# df_std = df.iloc[:, 1:].std()\n",
    "# df.iloc[:, 1:] = (df.iloc[:, 1:] - df_mean) / df_std\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df.iloc[:, 1:] = scaler.fit_transform(df.iloc[:, 1:])\n",
    "\n",
    "\n",
    "# # smell distribution\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# smell_counts = df['smell'].value_counts()\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.barplot(x=smell_counts.index, y=smell_counts.values)\n",
    "\n",
    "# plt.title('Distribution of \"Smell\" in Zipcode 15133')\n",
    "# plt.xlabel('Smell')\n",
    "# plt.ylabel('Distribution')\n",
    "# plt.xticks(rotation=45)  # Rotar las etiquetas del eje x para mejor legibilidad\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# one hot encoding\n",
    "df = pd.get_dummies(df, columns=['smell'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backdoor={}\n",
    "for var in df.columns:\n",
    "    backdoor[var]=['SONICWD_DEGsine', 'SONICWD_DEGcosine']\n",
    "\n",
    "print(backdoor)\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for col in ['H2S_PPM']:\n",
    "    values= list(set(df[col].values))\n",
    "    scores[col]=[]\n",
    "    for v in values:\n",
    "        print(v)\n",
    "        scores[col].append(get_query_output(df,'count','',[],[],['smell_egg'],[1],[col],[v],['*'],'',{}))#,{0:[1,2]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('scores_15133.json', 'w') as f:\n",
    "    json.dump(scores, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
